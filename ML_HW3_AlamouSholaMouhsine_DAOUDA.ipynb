{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c9e66e",
   "metadata": {},
   "source": [
    "Homework Guidelines: Building a Custom Neural Network for MNIST Digit Classification\n",
    "\n",
    "In this homework assignment, you are tasked with understanding and possibly modifying a Python script that trains a neural network to classify handwritten digits from the MNIST dataset. The provided code uses TensorFlow and Keras. Your goal is to comprehend the code and potentially make some modifications as indicated.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1 - Importing Libraries: Understand the initial part of the code where necessary libraries are imported. Ensure that you have TensorFlow and Keras installed in your environment.\n",
    "\n",
    "2- Loading the MNIST Dataset: Observe how the MNIST dataset is loaded and divided into training and testing sets. The dataset consists of images and labels.\n",
    "\n",
    "3- Data Preprocessing: Understand the normalization of pixel values to the range [0, 1]. This preprocessing step is essential for efficient model training.\n",
    "\n",
    "4- One-Hot Encoding: Comprehend the one-hot encoding process applied to the labels. It converts class labels into a binary matrix representation. Ensure that you understand the purpose of this transformation.\n",
    "\n",
    "5- Custom Dense Layer: Examine the custom dense layer definition. This layer is used within the neural network architecture and allows you to specify the number of units and activation function.\n",
    "\n",
    "    Pay attention to how weights and biases are initialized in the build method.\n",
    "    Understand how the layer performs matrix multiplication and applies the activation function in the call method.\n",
    "6- Neural Network Architecture: Analyze the definition of the neural network model. It consists of a series of layers, including custom dense layers with specified units and activation functions.\n",
    "\n",
    "    Identify the input shape for the first layer (28x28 for MNIST images).\n",
    "    Note the choice of activation functions (e.g., tf.nn.relu and tf.nn.softmax) for different layers.\n",
    "    \n",
    "7- Custom Loss Function: Study the custom loss function custom_sparse_categorical_crossentropy. This function computes the loss based on the negative log probabilities.\n",
    "\n",
    "    Understand how the negative log probabilities are calculated.\n",
    "    Observe how the mean loss across the batch is computed.\n",
    "8- Custom Accuracy Metric: Examine the custom_accuracy function, which calculates accuracy as the percentage of correct predictions.\n",
    "\n",
    "    Pay attention to how it compares predicted and true labels to determine accuracy.\n",
    "9- Model Compilation: Observe how the model is compiled using the Adam optimizer or other optimizer or you can write costum optimizer function, the custom loss function, and the custom accuracy metric.\n",
    "\n",
    "    Understand the significance of choosing appropriate optimizer and metrics for the task.\n",
    "10- Model Training: Check the training process using the model.fit method. The model is trained for a specified number of epochs and with a given batch size.\n",
    "\n",
    "11- Model Evaluation: Understand how the trained model is evaluated on the test dataset using the model.evaluate method. The test accuracy is printed as the result.\n",
    "\n",
    "Assignment Tasks (Optional):\n",
    "\n",
    "Experiment with different neural network architectures (e.g., changing the number of units, adding more layers, or trying different activation functions) to see how they affect model performance.\n",
    "\n",
    "Implement your custom loss function or metric and evaluate its impact on model training and performance.\n",
    "\n",
    "If you have a larger dataset, consider adapting this code to work with it by adjusting the input shape and the number of output units.\n",
    "\n",
    "Explore ways to visualize the model's predictions or intermediate layer activations to gain insights into its behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images =\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels = \n",
    "test_labels = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41af952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89a2d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/87/51/ad9ebf4ef29754b813a057d64a0634feb12aef27cabcbdb7433dc5cd4cb4/tensorflow-2.14.0-cp310-cp310-macosx_10_15_x86_64.whl.metadata\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-macosx_10_15_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting keras\n",
      "  Obtaining dependency information for keras from https://files.pythonhosted.org/packages/fe/58/34d4d8f1aa11120c2d36d7ad27d0526164b1a8ae45990a2fede31d0e59bf/keras-2.14.0-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m769.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/c9/ea/fe2a69cc6cfebf7c7ee8a6357566fc1cbb91632bde5869b669a396accb5f/libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes==0.2.0 (from tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes==0.2.0 from https://files.pythonhosted.org/packages/66/9f/3c133f83f3e5a7959345585e9ac715ef8bf6e8987551f240032e1b0d3ce6/ml_dtypes-0.2.0-cp310-cp310-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.23.5 in ./anaconda3/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in ./anaconda3/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/fe/f3/957db80e5b9f7fd7df97e5554fdc57919dfad24e89291223fd04a0e3c84f/protobuf-4.24.3-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading protobuf-4.24.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.10/site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./anaconda3/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/f8/54/d3923d9bbde098c60d1168ecf39025f02227b2037f2dd64ad460b2467b4a/tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-macosx_10_14_x86_64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.59.0.tar.gz (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboard<2.15,>=2.14 (from tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.15,>=2.14 from https://files.pythonhosted.org/packages/73/a2/66ed644f6ed1562e0285fcd959af17670ea313c8f331c46f79ee77187eb9/tensorboard-2.14.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.15,>=2.14.0 from https://files.pythonhosted.org/packages/d1/da/4f264c196325bb6e37a6285caec5b12a03def489b57cc1fdac02bb6272cd/tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.15,>=2.14->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/d7/88/1826b0c047c48763b36ed854a984127b430a16b70003155d7b19975f1d59/google_auth-2.23.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.28.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.15,>=2.14->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/37/52/da3f777c56fdcf3a484493ce58403c1af709709cd05dab9894980fc8d962/tensorboard_data_server-0.7.1-py3-none-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.2.2)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.14.0-cp310-cp310-macosx_10_15_x86_64.whl (229.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.6/229.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.24.3-cp37-abi3-macosx_10_9_universal2.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.4/409.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.23.2-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.1-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Building wheels for collected packages: grpcio\n",
      "  Building wheel for grpcio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpcio: filename=grpcio-1.59.0-cp310-cp310-macosx_10_10_x86_64.whl size=4293619 sha256=f46453d645f34396131ed2d6ee2d81b61195aad86db505ec2a574c120fddc63a\n",
      "  Stored in directory: /Users/wikiwoo/Library/Caches/pip/wheels/39/df/f6/fa6ebb064f5135e061766735a0e4d26d86f1cc7fc237c50fb9\n",
      "Successfully built grpcio\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.2 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 keras-2.14.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.3 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f25baf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 19.3442 - custom_accuracy: 0.9128\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 8.9056 - custom_accuracy: 0.9597\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 6.2332 - custom_accuracy: 0.9717\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 4.7513 - custom_accuracy: 0.9780\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 3.7320 - custom_accuracy: 0.9829\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.6765 - custom_accuracy: 0.9745\n",
      "Test accuracy number: 0.9745407104492188\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# Step 2: Loading the MNIST Dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Step 4: One-Hot Encoding\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "# Step 5: Custom Dense Layer\n",
    "class CustomDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\"weights\", (input_shape[-1], self.units))\n",
    "        self.b = self.add_weight(\"bias\", (self.units,))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z = tf.matmul(inputs, self.w) + self.b\n",
    "        if self.activation is not None:\n",
    "            return self.activation(z)\n",
    "        return z\n",
    "\n",
    "# Step 6: Neural Network Architecture\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Input shape for the first layer\n",
    "    CustomDenseLayer(128, activation=tf.nn.relu),\n",
    "    CustomDenseLayer(10, activation=tf.nn.softmax)  # Output layer with 10 units for 10 classes\n",
    "])\n",
    "\n",
    "# Step 7: Custom Loss Function\n",
    "def custom_sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred))\n",
    "    return loss\n",
    "\n",
    "# Step 8: Custom Accuracy Metric\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_predictions = tf.equal(tf.argmax(y_true, axis=1), tf.argmax(y_pred, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Step 9: Model Compilation\n",
    "model.compile(optimizer='adam',\n",
    "              loss=custom_sparse_categorical_crossentropy,\n",
    "              metrics=[custom_accuracy])\n",
    "\n",
    "# Step 10: Model Training\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "# Step 11: Model Evaluation\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy number:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e47a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
